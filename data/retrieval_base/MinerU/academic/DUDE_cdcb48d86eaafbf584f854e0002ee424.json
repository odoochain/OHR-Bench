[
    {
        "page_idx": 0,
        "text": "# \n# \nEdward Galvez, MPp - Wikimedia Foundation \n\n# \nThe Wikimedia movement has a history of doing surveys of their communities.[1] While the Wikimedia Foundation has traditionally conducted major editor surveys, it has been a few years since the last one was completed in 2012. Since then, demand for survey data has increased within the Foundation. Teams need data to make decisions about their work that affects communities. Teams often support the same communities, but they have very different goals. While the Survey Support Desk[2] is meant to support teams with their surveys, it would be challenging for one person to support them all. Therefore, doing surveys in this context brings up a two key problems: \n1. Complex surveys take time and expertise. Doing a complex survey can be too much work for a small group of people, and teams at the Foundation can be quite small. Surveys require significant expertise related to communication, planning, translation, analysis and reporting. Teams have to have the skills required, which often are not located in any one team.   \n2. Surveying the same people can cause fatigue. With teams sharing the communities they serve, a major risk was surveying communities too much, and causing survey fatigue for all who do surveys. \n# \n# \n\n# \nFirst, understanding the level of demand for surveys was crucial. In early Spring 2016, interviews were conducted with Wikimedia Foundation staff across various departments. We asked two questions: \"Who are the communities you serve?\"; and \"what long-term data do you need to make a decision?\" The main audiences identified were: Editors, Affiliates, Program leaders Volunteer developers, External partners,External researchers. The main data needs were attitudes, attributes & behaviors about: demographics, Wikimedia projects, software, programs, affiliates, and Wikimedia Foundationproducts&programs. \n[1] meta:Category:Surveys   \n[2] meta:Surveys   \n[3] meta:Community_Engagement_Insights   \n[4] meta:Community_Engagement_Insights/Sampling_strategy   \n[5] meta:CElnsights/2016-17_Survey_report \n# \nIn mid-2016, the survey process was implemented and called Community Engagement Insights.[3] The goal of the project was to (1) use surveys in order to improve alignment between the Foundation and Wikimedia communities (2) gather community feedback & needs (3) use it as a way to prevent survey fatigue. The survey went out to very active editors, active editors, Wikimedia affiliates, program leaders, and volunteer developers. \n\nOverall, demand for survey data was very high, and a process was needed that would encourage only those teams that needed data the most. We chose three ways to do this: \nA proposal-based process: Create a proposal process for teams to decide on their own if they can participate, with a heavy focus on team or project goals for choosing questions. Limit number of questions to 20 per team. Donation requirement: Teams were asked to donate time to the project: each team was expected to participate in one of 5 working groups: Communications, Community, Translations, Survey design, and Analysis. \n# \nPreparing the questions: 13 teams contributed questions from the Foundation.   \nAdministering the survey: At least 15 staff members supported the project in various ways. Volunteer support:Many community members supported reviewing the initial draft of the survey and helped with translating the survey.. Sampling & response rates: The sampling strategy was complex.[4] But in using stratified sampling for editors by wikimedia project. we had \\~5,100 responses, with response rates between $7.6\\%$ to $53.3\\%$   \nQuestion design: An initial mapping of movemen measures across various audiences was uncovered through this work. \n# \n# \nWhile a more robust retrospective is pending for next quarter, a few initial improvements have been identified: \nToo many questions: In this first year, the criteria for selecting questions was very loose in that the questions should align to the team's overall goals. What could be done to fix this problem? \nImproving the translation process: Volunteer translation took a lot of time for staff and volunteers. There was likely not enough time for volunteer translation of the survey. What could be done to fix this problem? \nThere are far too many people to thank, but here is a very short list: Benoit Evellin, User:Haytham Abulela, Maria Cruz, Montserrat Boix, Jorge Vargas Kalliope Tsouroupidou, Erica Lltrenta, Jeff Elder, User:Wargo, Nick Quiddity, User:Tsu-ya-, Neil Quinn, Jaime Anstee, User:Lyzzy, Lena Traer, User:Giaccai, User:Lucas, User:Eduardogobi, User:Frigory, Sati Houston, Vira Motorko, User:Takot, Cornelius Kibelka,User:Ata,User:星耀 晨曦 Delphine Menard, Sherry Snyder.. and so manymore! \n\n\nImproving community collaboration: Surveys are complex in the Wikimedia movement, where survey respondents are also often the ones who want to ask the question. How could we build a collaborative survey process? \n# \nImprovements to the sampling process: For very active editors, we had some very high response rates, but for active editors, our rates were much lower. Next year, we plan to work on increasing responses for all audiences. \n\n# \nwere developed related to the following goals. The goals below represent a subset, since we cannot fit them all: \n# \nimproving community health improving actual and/or perceived safety for all community members improving understanding of fundraising needs for the movement improve knowledge and capacity related to policy issues \n\nWikimediaProjects   \nimproving new editor engagement   \nincreasing capacity for GLAM and Libraries   \ncreating proactive public messaging strategy for Wikimedia projects   \nimproving research literacy of editors \n# \nimproving technology tools for contributing improving collaboration around product development growing our technical community with new developers \nWikimediaPrograms&Affiliates improving awareness & support for GLAM and Libraries increasing capacity around evaluation for affliates program leaders easing access to resources & people for program leaders/affliates Improving support to Wikimedia affiliate organizations \n# \nimproving communications related to affiliates/ program communities increasing the capacity of affliates Improve collaboration with affliates related to partnerships \nWikimediaFoundation   \nimproving collaboration and communications between Foundation   \nandcommunities   \nimproving various Foundation programs, such as Global Reach, fundraising. products, code of conduct, etc. \n\n#"
    }
]