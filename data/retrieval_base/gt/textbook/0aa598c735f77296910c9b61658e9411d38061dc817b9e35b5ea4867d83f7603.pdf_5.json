[
    {
        "text": "To possess evidence of sufficient validity, reliability, and treatment utility when administered by trained graduate students (as in this study). Two research studies provide the following technical adequacy data: test-retest reliability for function of .92 and agreement on function with direct observation results in 96% of cases (Borgmeier, 2003; McIntosh, Borgmeier, et al., 2008).\n\nProblem behavior ratings. Levels of behavior were measured through the Behavior Assessment Scale for Children 2 (BASC-2; Reynolds & Kamphaus, 2004). The BASC-2 is a standardized, norm-referenced behavior rating scale for assessing levels of problem behavior in school-aged students. The BASC-2 was selected because of its recent revision, its psychometric properties, and its updated, representative normative group. The measure also contains four validity indices to control for biased responding. The form used in this study was the BASC-2 Teacher Report Scale-Child Form, designed to rate the behavior of students aged 6 to 11 years. Composite scales for the BASC-2 are reported as T scores, with a mean of 50 and a standard deviation of 10. To measure level of problem behavior, the authors used the Behavioral Symptoms Index (BSI), a composite scale made up of the following subscales: hyperactivity, aggression, depression, attention problems, atypicality, and withdrawal. The BASC-2 test manual reports the following technical adequacy means for this composite scale: alpha reliability .97; test-retest reliability, .94; and inter-rater reliability, .64.\n\nProsocial behavior ratings. To measure level of prosocial behavior, the authors used the BASC-2 Teacher Report Scale-Child Form Adaptive Scale, a composite scale made up of the following subscales: adaptability, social skills, leadership, study skills, and functional communication. The BASC-2 test manual reports the following technical adequacy means for this composite scale: alpha reliability, .97; test-retest reliability, .89; and inter-rater reliability, .61.\n\nOffice discipline referrals. Office discipline referrals (ODRs) are school-based forms designed to document serious behavioral incidents and track individual student behavior (Sugai, Sprague, Horner, & Walker, 2000). School staff issue ODRs to students for serious behavioral violations, including fighting, vandalism, harassment, or noncompliance. ODRs have been shown to possess sufficient construct validity as a behavioral measure (Irvin, Tobin, Sprague, Sugai, & Vincent, 2004) and adequate concurrent validity with standardized behavior rating scales (McIntosh, Campbell, Carter, & Zumbo, 2008; B. Walker, Cheney, Stage, & Blum, 2005), and ODRs have been moderately correlated with other indirect measures of problem behavior, such as student self-report of delinquent behavior (Gottfredson & Gottfredson, 1999). In addition, the number and type of ODRs received significantly predict a range of future outcomes, including violent events in school and dropout (Tobin & Sugai, 1999). Predictive validity from one year to the next for middle and high school students has been documented at .54 (Gottfredson & Gottfredson, 1999), within the reported range of some standardized behavior rating scales.\n\nWhen incidents of problem behavior occur in the participating district, school personnel complete ODR forms, which are entered into the School-Wide Information System (SWIS; May et al., 2002), a Web-based ODR data system, to tally total ODRs per year. To increase the reliability of ODR data, the district conducts regular trainings on discriminating between behaviors that do and do not warrant a referral, based on definitions used in the SWIS.\n\n# Procedures\n\nThe Check-In/Check-Out intervention was implemented as described in the manual (Crone et al., 2003), with the school's tier one expectations used as the student behaviors to be rated (e.g., Safe, Respectful, Responsible) and no modification or individualization of goals or incentives. Before program implementation, the authors provided two 2-hour training sessions for school personnel and then provided monthly follow-up training sessions that stressed the critical features of the intervention and mechanisms of behavior improvement. The authors advised school administrators to identify school personnel with time at the start and finish of each day to serve as Check-In/Check-Out coordinators and mentors. In four of the schools, the school counselor served as the program coordinator and mentor for the participants. In one school, the special education teacher was the coordinator/mentor, and in the final school, an educational aide was the coordinator/mentor.\n\nStudents were referred to participate in the Check-In/Check-Out intervention by their classroom teachers through their usual school's request for assistance and behavior assistance team process. Prior to beginning the intervention, each student received a brief training session conducted by school personnel that (a) taught the daily routines of the Check-In/Check-Out program, (b) provided examples and non-examples of appropriate behavior in school, and (c) provided the student opportunities to practice the daily routines of the program. After training, the student began the program.\n\nMeasurement. Upon referral for behavior support and parent consent, the school notified the researchers and an",
        "page_idx": 0
    }
]